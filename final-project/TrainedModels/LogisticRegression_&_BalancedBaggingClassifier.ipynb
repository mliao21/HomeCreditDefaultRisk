{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 645 Final Project - Home Credit Default Risk\n",
    "\n",
    "## Overview\n",
    "-to predict how capable each applicant is able of repaying a loan\n",
    "\n",
    "## Model\n",
    "LogisticRegresion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "\n",
    "def print_grid_search_result(grid_search):\n",
    "    '''Prints summary of best model from GridSearchCV object.\n",
    "    \n",
    "        For the best model of the grid search, print:\n",
    "        - parameters \n",
    "        - cross-validation training score\n",
    "        \n",
    "        scores are printed with 3 decimal places.\n",
    "        grid_search (sklearn GridSearchCV): Fitted GridSearchCV object\n",
    "        returns: None\n",
    "\n",
    "    '''\n",
    "    print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "def plot_grid_search_results(grid_search):\n",
    "    '''For grids with 2 hyperparameters, create a heatmap plot of test scores\n",
    "        grid_search (sklearn GridSearchCV): Fitted GridSearchCV object\n",
    "        uses mglearn.tools.heatmap() for plotting.\n",
    "        \n",
    "    '''\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    params = sorted(grid_search.param_grid.keys())\n",
    "    assert len(params) == 2, \"We can only plot two parameters.\"\n",
    "    \n",
    "    # second dimension in reshape are rows, needs to be the fast changing parameter\n",
    "    scores = np.array(results.mean_test_score).reshape(len(grid_search.param_grid[params[0]]),\n",
    "                                                      len(grid_search.param_grid[params[1]]))\n",
    "\n",
    "    # plot the mean cross-validation scores\n",
    "    # x-axis needs to be the fast changing parameter\n",
    "    mglearn.tools.heatmap(scores, \n",
    "                          xlabel=params[1], \n",
    "                          xticklabels=grid_search.param_grid[params[1]], \n",
    "                          ylabel=params[0], \n",
    "                          yticklabels=grid_search.param_grid[params[0]],\n",
    "                          cmap=\"viridis\", fmt=\"%0.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb. of train samples: 64592\n",
      "Number of test samples:  35000\n",
      "Nb. features: 18\n",
      "Nb. of train samples after removing samples with no label: 59966\n",
      "Classes ratio (False/True): 5.305573\n",
      "\n",
      " Dataset Information (missing features, data type, unique values)\n",
      "                    Missing     Type  Unique\n",
      "default                   0    int64       2\n",
      "score_1                   0   object       7\n",
      "score_2                   0   object      35\n",
      "score_3                   0  float64      87\n",
      "score_4                   0  float64   59966\n",
      "score_5                   0  float64   59966\n",
      "score_6                   0  float64   59966\n",
      "risk_rate                 0  float64      81\n",
      "amount_borrowed           0  float64   50484\n",
      "borrowed_in_months        0  float64       2\n",
      "credit_limit          18779  float64   26238\n",
      "income                    0  float64   54273\n",
      "sign                  18938   object      12\n",
      "facebook_profile       5971   object       2\n",
      "state                     0   object      50\n",
      "real_state                0   object       5\n",
      "n_bankruptcies          202  float64       7\n",
      "n_defaulted_loans        18  float64       5\n",
      "n_accounts                0  float64      45\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np # makes Python better than MATLAB for array manipulation\n",
    "import pandas as pd # For reading and putting our CSV data in a shape suitable for processing \n",
    "\n",
    "# Traditional ML library\n",
    "import sklearn \n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.ensemble import BalancedBaggingClassifier,BalancedRandomForestClassifier # ML for imbalanced problems\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pylab as plt # for plotting\n",
    "\n",
    "\n",
    "# Features/columns to be removed for several reasons: ethical irrelevant feature, etc\n",
    "to_remove = [\"job_name\", \"reason\",\"channel\",\"n_issues\",\"ok_since\",\"zip\",\"gender\"] \n",
    "\n",
    "# Read train and test data and drop columns\n",
    "df_train = pd.read_csv(\"./Dataset/puzzle_train_dataset.csv\").set_index(\"ids\").drop(to_remove, axis=1)\n",
    "df_test = pd.read_csv(\"./Dataset/puzzle_test_dataset.csv\").set_index(\"ids\").drop(to_remove, axis=1)\n",
    "\n",
    "print(\"Nb. of train samples: %d\" %df_train.shape[0])\n",
    "print(\"Number of test samples:  %d\" %df_test.shape[0])\n",
    "print(\"Nb. features: %d\" %(df_train.shape[1]-1))\n",
    "\n",
    "# Remove samples with missing labels\n",
    "df_train = df_train[pd.notnull(df_train['default'])]\n",
    "df_train[\"default\"] = df_train[\"default\"].astype(\"int\")\n",
    "\n",
    "print(\"Nb. of train samples after removing samples with no label: %d\" %df_train.shape[0])\n",
    "print(\"Classes ratio (False/True): %f\" %((df_train[\"default\"] == 0).sum()/(df_train[\"default\"] == 1).sum()))\n",
    "\n",
    "\n",
    "# Dataset information\n",
    "feats_info = pd.concat([df_train.isnull().sum(), df_train.dtypes, df_train.T.apply(lambda x: x.nunique(), axis=1)], axis=1)\n",
    "feats_info.columns = [\"Missing\",\"Type\",\"Unique\"]\n",
    "print(\"\\n Dataset Information (missing features, data type, unique values)\")\n",
    "print(feats_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding and Feature Engineering\n",
    "Encoding categorical data into integer format.  \n",
    "Engineering new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(df, col):\n",
    "    dft = df[col].astype(str).to_frame().copy()\n",
    "    dft[\"count\"] = 1\n",
    "    return dft.groupby(col).count().to_dict()[\"count\"]\n",
    "    \n",
    "def encode_all(df_train, df_test, cols):\n",
    "    for col in cols:\n",
    "        enc = get_encoder(df_train, col)\n",
    "        df_train[col] = df_train[col].astype(str).apply(lambda x: enc.get(x, -1))\n",
    "        df_test[col] = df_test[col].astype(str).apply(lambda x: enc.get(x, -1))\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "# Create additional binary features flag for missing values for all features that have missing values\n",
    "for col in df_test.columns:\n",
    "    df_train[\"is_\" + col + \"_missing\"] = df_train[col].isnull() * 1\n",
    "    df_test[\"is_\" + col + \"_missing\"] = df_test[col].isnull() * 1\n",
    "\n",
    "# Represent categorical feature as a series o binary values and drop first column to avoid redundancy\n",
    "df_train = pd.get_dummies(df_train, columns=['score_1','score_2','real_state'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['score_1','score_2','real_state'], drop_first=True)\n",
    "\n",
    "encode_cols = df_train.dtypes\n",
    "encode_cols = encode_cols[encode_cols == object].index.tolist()\n",
    "\n",
    "\n",
    "# Encode categorical variables and replace NaN by -1\n",
    "df_train, df_test = encode_all(df_train, df_test, encode_cols)\n",
    "df_train, df_test = df_train.fillna(-1), df_test.fillna(-1)\n",
    "\n",
    "# Split features and labels\n",
    "X_train, y_train = df_train.drop([\"default\"], axis=1), df_train[\"default\"]\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search \n",
    "Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run. \n",
    "#Takes 2hrs to complete\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "            'C':[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "            'penalty':['none', 'l1', 'l2', 'elasticnet'],\n",
    "            'solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "            'fit_intercept':[True,False]\n",
    "            }\n",
    "\n",
    "logreg = LogisticRegression(max_iter=2000, random_state=1)\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print_grid_search_result(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting model with best hyperparameters   \n",
    "C = 0.1  \n",
    "fit_intercetp = True  \n",
    "penalty = l1  \n",
    "solver = liblinear  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994, 2)\n",
      "AUC score on fold 0: 0.757\n",
      "(11993, 2)\n",
      "AUC score on fold 1: 0.755\n",
      "(11993, 2)\n",
      "AUC score on fold 2: 0.753\n",
      "(11993, 2)\n",
      "AUC score on fold 3: 0.757\n",
      "(11993, 2)\n",
      "AUC score on fold 4: 0.756\n",
      "AUC: 0.756 +- 0.0015\n",
      "\n",
      "Confusion matrix:\n",
      "[[49806.   650.]\n",
      " [ 8335.  1175.]]\n",
      "\n",
      "Accuracy 0.850\n",
      "Accuracy = 0.850\n",
      "Precision = 0.644\n",
      "Recall = 0.124\n",
      "F1-score = 0.207\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.1, fit_intercept=True, penalty = 'l1', solver = 'liblinear', max_iter=2000, random_state = 1)\n",
    "skf = StratifiedKFold( 5, shuffle=True, random_state=100)\n",
    "cm = np.zeros((2,2))\n",
    "aucs = []\n",
    "for (fold, (i_train, i_test)) in enumerate(skf.split(X_train,y_train)):\n",
    "    logreg.fit(X_train.iloc[i_train], y_train.iloc[i_train])\n",
    "    i_pred_proba = logreg.predict_proba(X_train.iloc[i_test])\n",
    "    pred = logreg.predict(X_train.iloc[i_test])\n",
    "    print(i_pred_proba.shape)\n",
    "    auc = metrics.roc_auc_score(y_train.iloc[i_test], i_pred_proba[:, 1])\n",
    "    aucs.append(auc)\n",
    "    \n",
    "    cm += metrics.confusion_matrix(y_train.iloc[i_test],pred)\n",
    "    print(\"AUC score on fold %i: %2.3f\" % (fold, auc))\n",
    "print(\"AUC: %2.3f +- %2.4f\" % (np.mean(aucs), np.std(aucs)))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nAccuracy %2.3f\" %(cm.diagonal().sum()/cm.sum()))\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "TN = cm[0][0]\n",
    "TP = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"Accuracy = %2.3f\" %(cm.diagonal().sum()/cm.sum()))\n",
    "print(\"Precision = %2.3f\" %precision)\n",
    "print(\"Recall = %2.3f\" %recall)\n",
    "print(\"F1-score = %2.3f\" %f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Using Recursive Feature Elimination (RFE) to select most relavant in predicting the target variable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "predictors = X_train\n",
    "selector = RFE(logreg, n_features_to_select=1)\n",
    "selector = selector.fit(predictors,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order and print out feature ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'score_3'), (2, 'score_4'), (3, 'score_5'), (4, 'score_6'), (5, 'risk_rate'), (6, 'amount_borrowed'), (7, 'borrowed_in_months'), (8, 'credit_limit'), (9, 'income'), (10, 'sign'), (11, 'facebook_profile'), (12, 'state'), (13, 'n_bankruptcies'), (14, 'n_defaulted_loans'), (15, 'n_accounts'), (16, 'is_score_1_missing'), (17, 'is_score_2_missing'), (18, 'is_score_3_missing'), (19, 'is_score_4_missing'), (20, 'is_score_5_missing'), (21, 'is_score_6_missing'), (22, 'is_risk_rate_missing'), (23, 'is_amount_borrowed_missing'), (24, 'is_borrowed_in_months_missing'), (25, 'is_credit_limit_missing'), (26, 'is_income_missing'), (27, 'is_sign_missing'), (28, 'is_facebook_profile_missing'), (29, 'is_state_missing'), (30, 'is_real_state_missing'), (31, 'is_n_bankruptcies_missing'), (32, 'is_n_defaulted_loans_missing'), (33, 'is_n_accounts_missing'), (34, 'score_1_4DLlLW62jReXaqbPaHp1vQ=='), (35, 'score_1_8k8UDR4Yx0qasAjkGrUZLw=='), (36, 'score_1_DGCQep2AE5QRkNCshIAlFQ=='), (37, 'score_1_e4NYDor1NOw6XKGE60AWFw=='), (38, 'score_1_fyrlulOiZ+5hoFqLa6UbDQ=='), (39, 'score_1_smzX0nxh5QlePvtVf6EAeg=='), (40, 'score_2_+CxEO4w7jv3QPI/BQbyqAA=='), (41, 'score_2_/tdlnWjXoZ3OjdtBXzdOJQ=='), (42, 'score_2_5/uMrqKj3OL/Xk5OrGx9fg=='), (43, 'score_2_55UK234RR1d7HIWJjmq9tw=='), (44, 'score_2_6J1ZMTzN5GKHXnhM4J1JbA=='), (45, 'score_2_7h+tk4z7O9brtBSe1rNjxA=='), (46, 'score_2_7h8PTkrlTWUPP3yuyP4rUg=='), (47, 'score_2_A+QuW1n/ABeiVVe/9CRZ9Q=='), (48, 'score_2_Fv28Bz0YRTVAT5kl1bAV6g=='), (49, 'score_2_IOVu8au3ISbo6+zmfnYwMg=='), (50, 'score_2_LCak332j+TYFqHC3NDwiqg=='), (51, 'score_2_NLvAOzzmJba/0zolQnWF5Q=='), (52, 'score_2_O4i7FxcROACMVTCgI0WXuA=='), (53, 'score_2_OlDYtdljgSSYM/M1L2CRaQ=='), (54, 'score_2_RO7MTL+j4PH2gNzbhNTq/A=='), (55, 'score_2_SaamrHMo23l/3TwXOWgVzw=='), (56, 'score_2_YLGMUI9hObSh6wD/xfanGg=='), (57, 'score_2_bopP0NxW3+r8tn9xIHTaOw=='), (58, 'score_2_cdpgyOyZS04uXerMNu7uCw=='), (59, 'score_2_d/7Hedyz7ovK9Pn1CYN4+A=='), (60, 'score_2_dCm9hFKfdRm7ej3jW+gyxw=='), (61, 'score_2_dWJRASUFMejk3AHZ1p1Gkg=='), (62, 'score_2_emS9xH8CLoRNie2uSmaDAQ=='), (63, 'score_2_ky19q4V1ZqgL3jnHX0wKDw=='), (64, 'score_2_mX2VRRG38RPiHX+MfjefRw=='), (65, 'score_2_osCzpM4hJrxugqWWuZmMWw=='), (66, 'score_2_pAzpxkhjPsjWldgSX21+zg=='), (67, 'score_2_rJZgTmANW3PjOCQLCcp4iQ=='), (68, 'score_2_tHpS8e9F8d9zg3iOQM9tsA=='), (69, 'score_2_tQUTfUyeuGkhRotd+6WjVg=='), (70, 'score_2_vJyc9xom9v7hwFMPTIpmKw=='), (71, 'score_2_w1miZqhB5+RSamEQJa0rqg=='), (72, 'score_2_wjdj2vxjWoDsEIk0l09ynw=='), (73, 'score_2_wkeCdGeu5sEv4/fjwR0aDg=='), (74, 'real_state_N5/CE7lSkAfB04hVFFwllw=='), (75, 'real_state_UX7AdFYgQh+VrVC5eIaU9w=='), (76, 'real_state_n+xK9CfX0bCn77lClTWviw=='), (77, 'real_state_nSpvDsIsslUaX6GE6m6eQA==')]\n"
     ]
    }
   ],
   "source": [
    "order = selector.ranking_\n",
    "feature_ranks_dict= {}\n",
    "for i in selector.ranking_:\n",
    "    feature_ranks_dict[i]=X_train.columns[i-1]\n",
    "\n",
    "feature_ranks_dict_items=feature_ranks_dict.items()\n",
    "sorted_dict = sorted(feature_ranks_dict_items)\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model on Test data\n",
    "Create output csv file \"predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e4366223-7aa2-0904-7a47-66479ae46b2a</th>\n",
       "      <td>0.086984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6416108-c6d7-e6be-c4b5-923dd36c8ec4</th>\n",
       "      <td>0.142029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a90d3929-86ec-2414-89ba-543776b0e82b</th>\n",
       "      <td>0.153835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5b96a7f-389a-28d0-242d-95db05e69da0</th>\n",
       "      <td>0.550139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b461faa-926d-565d-b15d-0b452968ac81</th>\n",
       "      <td>0.176417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfe269ae-b893-c084-f9f5-3b91f9725b71</th>\n",
       "      <td>0.141661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2feff27a-3dcf-1e19-7583-a8eab192fd23</th>\n",
       "      <td>0.051271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601509fd-20d9-d3b8-b143-defcf5457d2c</th>\n",
       "      <td>0.139706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0168e1c-ddbd-1b2c-acfb-f09638e1ee34</th>\n",
       "      <td>0.060648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508276ff-56cb-243c-da1d-4929c1411344</th>\n",
       "      <td>0.113770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      predictions\n",
       "ids                                              \n",
       "e4366223-7aa2-0904-7a47-66479ae46b2a     0.086984\n",
       "c6416108-c6d7-e6be-c4b5-923dd36c8ec4     0.142029\n",
       "a90d3929-86ec-2414-89ba-543776b0e82b     0.153835\n",
       "c5b96a7f-389a-28d0-242d-95db05e69da0     0.550139\n",
       "1b461faa-926d-565d-b15d-0b452968ac81     0.176417\n",
       "...                                           ...\n",
       "cfe269ae-b893-c084-f9f5-3b91f9725b71     0.141661\n",
       "2feff27a-3dcf-1e19-7583-a8eab192fd23     0.051271\n",
       "601509fd-20d9-d3b8-b143-defcf5457d2c     0.139706\n",
       "b0168e1c-ddbd-1b2c-acfb-f09638e1ee34     0.060648\n",
       "508276ff-56cb-243c-da1d-4929c1411344     0.113770\n",
       "\n",
       "[35000 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "my_predictions = pd.DataFrame(logreg.predict_proba(X_test)[:, 1], columns=[\"predictions\"], index=X_test.index)\n",
    "my_predictions.to_csv(\"logreg_predictions.csv\")\n",
    "my_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'base_estimator': LogisticRegression(C=0.1, max_iter=2000, penalty='l1', random_state=1,\n",
      "                   solver='liblinear'), 'n_estimators': 1}\n",
      "Best cross-validation score: 0.693\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization with GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "param_grid = {\n",
    "            'base_estimator':[LogisticRegression(C=0.1, max_iter=2000, penalty='l1', random_state=1,solver='liblinear')],\n",
    "            'n_estimators':[1, 10, 50, 100]\n",
    "            }\n",
    "\n",
    "bb_clf = BalancedBaggingClassifier(random_state=1)\n",
    "grid_search = GridSearchCV(bb_clf, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print_grid_search_result(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994, 2)\n",
      "AUC score on fold 0: 0.754\n",
      "(11993, 2)\n",
      "AUC score on fold 1: 0.753\n",
      "(11993, 2)\n",
      "AUC score on fold 2: 0.752\n",
      "(11993, 2)\n",
      "AUC score on fold 3: 0.757\n",
      "(11993, 2)\n",
      "AUC score on fold 4: 0.754\n",
      "AUC: 0.754 +- 0.0017\n",
      "\n",
      "Confusion matrix:\n",
      "[[35057. 15399.]\n",
      " [ 3065.  6445.]]\n",
      "\n",
      "Accuracy 0.692\n",
      "Accuracy = 0.692\n",
      "Precision = 0.295\n",
      "Recall = 0.678\n",
      "F1-score = 0.411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bb_clf = BalancedBaggingClassifier(base_estimator=LogisticRegression(C=0.1, max_iter=2000, penalty='l1', random_state=1,solver='liblinear'), random_state=1, n_estimators=1)\n",
    "skf = StratifiedKFold( 5, shuffle=True, random_state=100)\n",
    "cm2 = np.zeros((2,2))\n",
    "aucs2 = []\n",
    "for (fold, (i_train, i_test)) in enumerate(skf.split(X_train,y_train)):\n",
    "    bb_clf.fit(X_train.iloc[i_train], y_train.iloc[i_train])\n",
    "    i_pred_proba = bb_clf.predict_proba(X_train.iloc[i_test])\n",
    "    pred = bb_clf.predict(X_train.iloc[i_test])\n",
    "    print(i_pred_proba.shape)\n",
    "    auc = metrics.roc_auc_score(y_train.iloc[i_test], i_pred_proba[:, 1])\n",
    "    aucs2.append(auc)\n",
    "    \n",
    "    cm2 += metrics.confusion_matrix(y_train.iloc[i_test],pred)\n",
    "    print(\"AUC score on fold %i: %2.3f\" % (fold, auc))\n",
    "print(\"AUC: %2.3f +- %2.4f\" % (np.mean(aucs2), np.std(aucs2)))\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm2)\n",
    "print(\"\\nAccuracy %2.3f\" %(cm2.diagonal().sum()/cm2.sum()))\n",
    "\n",
    "TN = cm2[0][0]\n",
    "TP = cm2[1][1]\n",
    "FN = cm2[1][0]\n",
    "FP = cm2[0][1]\n",
    "\n",
    "accuracy = (TP+TN)/(TP+TN+FN+FP)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"Accuracy = %2.3f\" %(cm2.diagonal().sum()/cm2.sum()))\n",
    "print(\"Precision = %2.3f\" %precision)\n",
    "print(\"Recall = %2.3f\" %recall)\n",
    "print(\"F1-score = %2.3f\" %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e4366223-7aa2-0904-7a47-66479ae46b2a</th>\n",
       "      <td>0.086984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6416108-c6d7-e6be-c4b5-923dd36c8ec4</th>\n",
       "      <td>0.142029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a90d3929-86ec-2414-89ba-543776b0e82b</th>\n",
       "      <td>0.153835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5b96a7f-389a-28d0-242d-95db05e69da0</th>\n",
       "      <td>0.550139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b461faa-926d-565d-b15d-0b452968ac81</th>\n",
       "      <td>0.176417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfe269ae-b893-c084-f9f5-3b91f9725b71</th>\n",
       "      <td>0.141661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2feff27a-3dcf-1e19-7583-a8eab192fd23</th>\n",
       "      <td>0.051271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601509fd-20d9-d3b8-b143-defcf5457d2c</th>\n",
       "      <td>0.139706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0168e1c-ddbd-1b2c-acfb-f09638e1ee34</th>\n",
       "      <td>0.060648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508276ff-56cb-243c-da1d-4929c1411344</th>\n",
       "      <td>0.113770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      predictions\n",
       "ids                                              \n",
       "e4366223-7aa2-0904-7a47-66479ae46b2a     0.086984\n",
       "c6416108-c6d7-e6be-c4b5-923dd36c8ec4     0.142029\n",
       "a90d3929-86ec-2414-89ba-543776b0e82b     0.153835\n",
       "c5b96a7f-389a-28d0-242d-95db05e69da0     0.550139\n",
       "1b461faa-926d-565d-b15d-0b452968ac81     0.176417\n",
       "...                                           ...\n",
       "cfe269ae-b893-c084-f9f5-3b91f9725b71     0.141661\n",
       "2feff27a-3dcf-1e19-7583-a8eab192fd23     0.051271\n",
       "601509fd-20d9-d3b8-b143-defcf5457d2c     0.139706\n",
       "b0168e1c-ddbd-1b2c-acfb-f09638e1ee34     0.060648\n",
       "508276ff-56cb-243c-da1d-4929c1411344     0.113770\n",
       "\n",
       "[35000 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "my_predictions = pd.DataFrame(logreg.predict_proba(X_test)[:, 1], columns=[\"predictions\"], index=X_test.index)\n",
    "my_predictions.to_csv(\"bb_clf.csv\")\n",
    "my_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
